import numpy as np
import pandas as pd

class SmartHomeEnv:
    """
    Custom Environment for PPO Agent to learn Appliance Scheduling
    """
    def __init__(self, data_path='data/next_day_prediction.csv'):
        # Load the forecast data generated by XGBoost
        self.df = pd.read_csv(data_path)
        self.current_step = 0
        self.max_steps = len(self.df) - 1
        
        # Action Space: 0 = No Change, 1 = Shift/Reduce Load
        # State Space: [Hour, Price, Occupancy, Predicted_Load]
        
    def reset(self):
        self.current_step = 0
        return self._get_observation()

    def _get_observation(self):
        row = self.df.iloc[self.current_step]
        return np.array([
            row['hour'] if 'hour' in row else 0,
            row['electricity_price'],
            row['occupancy'],
            row['Heater'] + row['Washing Machine']
        ], dtype=np.float32)

    def step(self, action):
        """
        Action 0: Standard Operation
        Action 1: PPO Optimized (Reduce/Shift)
        """
        row = self.df.iloc[self.current_step]
        price = row['electricity_price']
        base_load = row['Fridge'] + row['Lights']
        controllable_load = row['Heater'] + row['Washing Machine']
        
        # Apply Action
        if action == 1:
            # Agent decides to reduce/shift 70% of controllable load
            actual_load = base_load + (controllable_load * 0.3)
            discomfort_penalty = 0.1 * controllable_load # User feels slight cold/delay
        else:
            actual_load = base_load + controllable_load
            discomfort_penalty = 0
            
        # Calculate Reward: (Negative Cost) - (Discomfort)
        cost = actual_load * price
        reward = -(cost + discomfort_penalty)
        
        self.current_step += 1
        done = self.current_step >= self.max_steps
        obs = self._get_observation()
        
        return obs, reward, done, {"cost": cost, "load": actual_load}

# Example of how the agent 'thinks' for your paper
def simulate_ppo_decision(price, occupancy):
    """
    Simple logic used by the Digital Twin to mimic the PPO Agent
    """
    if price > 0.6 and occupancy < 2:
        return 1  # Action: Optimize
    return 0      # Action: Normal
